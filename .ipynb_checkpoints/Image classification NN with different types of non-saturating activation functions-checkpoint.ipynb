{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62872e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c70aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# define num_class\n",
    "num_classes = 10\n",
    "\n",
    "# load dataset keras will download cifar-10 datset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()  \n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd7e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting class vectors to binary class matrices.\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb42665",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61efa5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 14:12:12.522366: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-13 14:12:12.522647: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# standardizing the input features\n",
    "# Calculate the mean and standard deviation of the training set\n",
    "mean = tf.reduce_mean(x_train, axis=(0, 1, 2))\n",
    "std = tf.math.reduce_std(x_train, axis=(0, 1, 2))\n",
    "\n",
    "# Standardize the input features using mean and standard deviation\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791d127",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212dc8e",
   "metadata": {},
   "source": [
    "### Relu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a360598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing the layer architecture of the DNN model\n",
    "LAYERS = [\n",
    "          tf.keras.layers.Flatten(input_shape=[32, 32,3], name=\"inputLayer\"),\n",
    "          tf.keras.layers.Dense(300, activation=\"relu\", name=\"hiddenLayer1\"),\n",
    "          tf.keras.layers.Dense(200, activation=\"relu\", name=\"hiddenLayer2\"),\n",
    "          tf.keras.layers.Dense(100, activation=\"relu\", name=\"hiddenLayer3\"),\n",
    "          tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3749ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_relu = model_relu.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab830ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba7477",
   "metadata": {},
   "source": [
    "Training accuracy: 71%\n",
    "Testing accuracy: 51.38%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e34b48",
   "metadata": {},
   "source": [
    "### Leaky-relu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b969a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing the layer architecture of the DNN model\n",
    "LAYERS = [\n",
    "          tf.keras.layers.Flatten(input_shape=[32, 32,3], name=\"inputLayer\"),\n",
    "          tf.keras.layers.Dense(300, activation=tf.keras.layers.LeakyReLU(alpha=0.01), name=\"hiddenLayer1\"),\n",
    "          tf.keras.layers.Dense(200, activation=tf.keras.layers.LeakyReLU(alpha=0.01), name=\"hiddenLayer2\"),\n",
    "          tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.01), name=\"hiddenLayer3\"),\n",
    "          tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a112140",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Leakyrelu = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_Leakyrelu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffa705",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_Leakyrelu = model_Leakyrelu.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Leakyrelu.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848b630",
   "metadata": {},
   "source": [
    "Training accuracy: 74.25%\n",
    "Testing accuracy: 50.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc6b52",
   "metadata": {},
   "source": [
    "### Randomized Leaky Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f07fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for randomized Leaky ReLU activation\n",
    "class RandomizedLeakyReLU(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RandomizedLeakyReLU, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        alpha = tf.random.uniform(shape=tf.shape(inputs), minval=0.01, maxval=0.2)\n",
    "        return tf.maximum(alpha * inputs, inputs)\n",
    "\n",
    "# Modify the layers to use randomized Leaky ReLU activation\n",
    "LAYERS = [\n",
    "    tf.keras.layers.Flatten(input_shape=[32, 32, 3], name=\"inputLayer\"),\n",
    "    tf.keras.layers.Dense(300, name=\"hiddenLayer1\"),\n",
    "    RandomizedLeakyReLU(name=\"hiddenLayer1_activation\"),\n",
    "    tf.keras.layers.Dense(200, name=\"hiddenLayer2\"),\n",
    "    RandomizedLeakyReLU(name=\"hiddenLayer2_activation\"),\n",
    "    tf.keras.layers.Dense(100, name=\"hiddenLayer3\"),\n",
    "    RandomizedLeakyReLU(name=\"hiddenLayer3_activation\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2523c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RandomizedLeakyrelu = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ddadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_RandomizedLeakyrelu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_RandomizedLeakyrelu = model_RandomizedLeakyrelu.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a809de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RandomizedLeakyrelu.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3593a",
   "metadata": {},
   "source": [
    "Training accuracy: 74%\n",
    "Testing Accuracy: 54.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a27d54",
   "metadata": {},
   "source": [
    "### Parametric Leaky Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modify the layers to use Parametric Leaky ReLU activation\n",
    "LAYERS = [\n",
    "    tf.keras.layers.Flatten(input_shape=[32, 32, 3], name=\"inputLayer\"),\n",
    "    tf.keras.layers.Dense(300, name=\"hiddenLayer1\"),\n",
    "    tf.keras.layers.PReLU(name=\"hiddenLayer1_activation\"),\n",
    "    tf.keras.layers.Dense(200, name=\"hiddenLayer2\"),\n",
    "    tf.keras.layers.PReLU(name=\"hiddenLayer2_activation\"),\n",
    "    tf.keras.layers.Dense(100, name=\"hiddenLayer3\"),\n",
    "    tf.keras.layers.PReLU(name=\"hiddenLayer3_activation\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293218e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ParaLeakyrelu = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_ParaLeakyrelu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba79956",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ParaLeakyrelu = model_ParaLeakyrelu.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ParaLeakyrelu.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6d27d",
   "metadata": {},
   "source": [
    "training accuracy: 75.88%\n",
    "testing accuracy: 51.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5927ac",
   "metadata": {},
   "source": [
    "### Exponential Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the layers to use ELU activation\n",
    "LAYERS = [\n",
    "    tf.keras.layers.Flatten(input_shape=[32, 32, 3], name=\"inputLayer\"),\n",
    "    tf.keras.layers.Dense(300, activation=\"elu\", name=\"hiddenLayer1\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"elu\", name=\"hiddenLayer2\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"elu\", name=\"hiddenLayer3\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\", name=\"outputLayer\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d635a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elu = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_elu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89508da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_elu = model_elu.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be92695",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elu.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e397ce4",
   "metadata": {},
   "source": [
    "training accuracy: 82%\n",
    "testing accuracy: 51.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede5515",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the layers to use ELU activation\n",
    "LAYERS = [\n",
    "    tf.keras.layers.Flatten(input_shape=[32, 32, 3], name=\"inputLayer\"),\n",
    "    tf.keras.layers.Dense(300, activation=\"selu\", kernel_initializer = \"lecun_normal\" ,name=\"hiddenLayer1\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"selu\", kernel_initializer = \"lecun_normal\" , name=\"hiddenLayer2\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"selu\", kernel_initializer = \"lecun_normal\" , name=\"hiddenLayer3\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"selu\", kernel_initializer = \"lecun_normal\" , name=\"outputLayer\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selu = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1149547",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_selu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_selu = model_selu.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee8b5b",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a93c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn = keras.models.Sequential([\n",
    "    keras. layers.Flatten(input_shape= [32,32,3]),\n",
    "    keras. layers. BatchNormalization(), \n",
    "    keras. layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras. layers.Activation(\"elu\"),\n",
    "    keras. layers. Dense(100, kernel_initializer=\"he_normal\", use_bias=False), \n",
    "    keras. layers.Activation(\"elu\"), \n",
    "    keras. layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_bn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63135a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bn = model_bn.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 128,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a21ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe62aa0",
   "metadata": {},
   "source": [
    "Training accuracy: 91%\n",
    "Testing accuracy: 52.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951111c8",
   "metadata": {},
   "source": [
    "## Learning rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98bcc7d",
   "metadata": {},
   "source": [
    "1. Exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19528786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(epoch,lr):\n",
    "    return lr*0.1**(1/20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd6939",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay)\n",
    "history_bn2 = model_bn.fit(x_train,y_train,\n",
    "                          epochs=50,batch_size=32,\n",
    "                          validation_data=(x_test,y_test),\n",
    "                          callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11647b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03995133",
   "metadata": {},
   "source": [
    "Training accuracy: 74%\n",
    "Testing accuracy: 55.36%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69b7c3",
   "metadata": {},
   "source": [
    "2. Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_performanceScheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db763f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bn3 = model_bn.fit(x_train,y_train,\n",
    "                          epochs=50,batch_size=32,\n",
    "                          validation_data=(x_test,y_test),\n",
    "                          callbacks=[lr_performanceScheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a86f0",
   "metadata": {},
   "source": [
    "Training Accuracy: 81%\n",
    "Testing Accuracy: 55.6%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc32740",
   "metadata": {},
   "source": [
    "### Fixing Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f525eb91",
   "metadata": {},
   "source": [
    "#### 1. L1 and L2 regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn_l1_l2 = keras.models.Sequential([\n",
    "    keras. layers.Flatten(input_shape= [32,32,3]),\n",
    "    keras. layers. BatchNormalization(), \n",
    "    keras. layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False,kernel_regularizer = keras.regularizers.l1_l2(0.01)),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras. layers.Activation(\"elu\"),\n",
    "    keras. layers. Dense(100, kernel_initializer=\"he_normal\", use_bias=False,kernel_regularizer = keras.regularizers.l1_l2(0.01)), \n",
    "    keras. layers.Activation(\"elu\"), \n",
    "    keras. layers.BatchNormalization(), \n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_bn_l1_l2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40795ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_bn_l1_l2 = model_bn_l1_l2.fit(x_train,y_train, \n",
    "              epochs=50,batch_size = 32,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebe511",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn_l1_l2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b53e4f",
   "metadata": {},
   "source": [
    "Training Accuracy: 35%\n",
    "Testing Accuracy: 35.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f4fd7",
   "metadata": {},
   "source": [
    "#### 2. Dropout technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c4f8e",
   "metadata": {},
   "source": [
    "We will force dropout technique to be active during both training and validation, this is to get the exact idea if the model is overfitting or not.\n",
    "\n",
    "Also we will add dropout layer only after the last hidden layer, since this is followed by most architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn_dropout = keras.models.Sequential([\n",
    "    keras. layers.Flatten(input_shape= [32,32,3]),\n",
    "    keras. layers. BatchNormalization(), \n",
    "    keras. layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(), \n",
    "    keras. layers.Activation(\"elu\"),\n",
    "    keras. layers. Dense(100, kernel_initializer=\"he_normal\", use_bias=False), \n",
    "    keras. layers.Activation(\"elu\"), \n",
    "    keras. layers.BatchNormalization(), \n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10dc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model_bn_dropout.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras.backend.learning_phase_scope(1):\n",
    "    history_bn_dropout = model_bn_dropout.fit(x_train,y_train, \n",
    "                  epochs=50,batch_size = 32,\n",
    "                  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn_dropout.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2bcfd3",
   "metadata": {},
   "source": [
    "### Final model by default DNN configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a0cd9",
   "metadata": {},
   "source": [
    "1. Kernel_initializer = LeCun Initialization\n",
    "2. Activation function: SELU\n",
    "3. Normalization = none\n",
    "4. regularization = early stopping\n",
    "5. optimizer = nadam\n",
    "6. learning rate scheduler = performance scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32,32,3]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_performanceScheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5481f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_finalDNN = model.fit(x_train,y_train,\n",
    "                          epochs=50,batch_size=32,\n",
    "                          validation_data=(x_test,y_test),\n",
    "                          callbacks=[lr_performanceScheduler, early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
